{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch基础语法目录\n",
    "Pytorch生成张量的方式<br/>\n",
    "Pytorch nn.module类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pytorch生成张量的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################全为一样的数字####################################################\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.5000, 1.5000, 1.5000],\n",
      "        [1.5000, 1.5000, 1.5000],\n",
      "        [1.5000, 1.5000, 1.5000],\n",
      "        [1.5000, 1.5000, 1.5000],\n",
      "        [1.5000, 1.5000, 1.5000]])\n",
      "tensor([[66, 66, 66],\n",
      "        [66, 66, 66]])\n",
      "##############################范围数字########################################################\n",
      "tensor([ 2.0000,  4.1000,  6.2000,  8.3000, 10.4000, 12.5000, 14.6000])\n",
      "tensor([ 1.0000,  3.2500,  5.5000,  7.7500, 10.0000])\n",
      "tensor([[1, 2, 7],\n",
      "        [0, 2, 7],\n",
      "        [0, 6, 1]])\n",
      "##############################特定分布的矩阵##################################################\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "我是1729种子生成的随机数，范围是[0,1),服从均匀分布:\n",
      "tensor([[0.3126, 0.3791],\n",
      "        [0.3087, 0.0736]])\n",
      "tensor([[-1.3975,  1.4364],\n",
      "        [-0.1068, -0.8413]])\n",
      "\n",
      "我是高斯白噪声，服从标准正态分布（均值为0，方差为1），:\n",
      "在-1.96～+1.96范围内曲线下的面积等于0.9500，在-2.58～+2.58范围内曲线下面积为0.9900\n",
      "tensor([[ 0.0144, -2.6373],\n",
      "        [-0.4331,  0.4472]])\n"
     ]
    }
   ],
   "source": [
    "print('############################全为一样的数字####################################################')\n",
    "z = torch.zeros(5, 3)\n",
    "print(z)\n",
    "z = torch.ones(5, 3)\n",
    "print(z)\n",
    "z = torch.ones(5, 3)*1.5 # 和Numpy一样，torch也支持广播机制(向量*标量)\n",
    "print(z)\n",
    "z=torch.full((2,3),66)\n",
    "print(z)\n",
    "print(\"##############################范围数字########################################################\")\n",
    "z=torch.arange(2,15,2.1) #和Numpy一样，左闭右开[),最后一个参数可以省略，缺省为1\n",
    "print(z)\n",
    "z= torch.linspace(1,10,5) #[1,10]是数据范围，5是数据个数\n",
    "print(z)\n",
    "f = torch.randint(0, 10, (3, 3))  # 生成0(包含)到10(不包含)之间均匀分布整数的3X3矩阵\n",
    "print(f)\n",
    "print(\"##############################特定分布的矩阵##################################################\")\n",
    "z = torch.eye(3) # 生成3*3的单位矩阵\n",
    "print(z)\n",
    "\n",
    "torch.manual_seed(1729) #一个随机种子，每次调用torch.rand()都是一个不同的种子,种子可以作用在所有随即方法。\n",
    "r1 = torch.rand(2, 2)\n",
    "print('我是1729种子生成的随机数，范围是[0,1),服从均匀分布:')\n",
    "print(r1)\n",
    "\n",
    "normal_a = torch.normal(mean = torch.full([2, 2], 0.),std = torch.full([2, 2], 1.))\n",
    "print(normal_a)\n",
    "\n",
    "torch.manual_seed(200)#随机种子，每次都会不同，可以写两个相同的种子在rand方法上，生成的矩阵也相等。\n",
    "r4=torch.randn(2, 2) \n",
    "print('\\n我是高斯白噪声，服从标准正态分布（均值为0，方差为1），:')\n",
    "print('在-1.96～+1.96范围内曲线下的面积等于0.9500，在-2.58～+2.58范围内曲线下面积为0.9900')\n",
    "print(r4)\n",
    "\n",
    "\n",
    "#除此之外，numpy类型的array都可以转化成torch\n",
    "a=np.array([1,2,3])\n",
    "z=torch.tensor(a) # 等价于torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Pytorch基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [5]])\n",
      "C:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]]) \n",
      "C.shape:\n",
      " torch.Size([6, 3]) \n",
      "\n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n",
      "tensor([[1.5000, 1.5000, 1.5000],\n",
      "        [1.5000, 1.5000, 1.5000]])\n",
      "tensor([[3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]])\n",
      "矩阵C的size是:\n",
      "torch.Size([2, 3])\n",
      "2\n",
      "矩阵C的参数个数是:\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#tensor的截取，拼接\n",
    "data=torch.tensor([[1,2,3],[4,5,6]])\n",
    "data2=torch.tensor([[10,20,30],[40,50,60]])\n",
    "print(data[0:2,1:2]) #左闭右开\n",
    "\n",
    "A=torch.ones(2,3)    #2x3的张量（矩阵）\n",
    "B=2*torch.ones(4,3)  #4x3的张量（矩阵）\n",
    "C=torch.cat((A,B),0)  #按维数0（行）拼接\n",
    "print(\"C:\\n\",C,\"\\nC.shape:\\n\",C.shape,\"\\n\")\n",
    "\n",
    "#相加操作，函数名带有下划线表示改变对象的值，不带下划线表示需要赋值给别人。\n",
    "A.add_(3)#广播\n",
    "D=torch.ones(2,3)    #2x3的张量（矩阵）\n",
    "A.add_(D)\n",
    "print(A)\n",
    "\n",
    "#相乘操作与矩阵乘法\n",
    "A=torch.ones(2,3) \n",
    "B=torch.ones(3,10)\n",
    "C=torch.ones(2,3)*1.5\n",
    "print(A*C)\n",
    "print(A@B)\n",
    "torch.mm(A,B.t().t())  #这里为了演示t()表示转置\n",
    "\n",
    "#size与numel\n",
    "print(\"矩阵C的size是:\")\n",
    "print(C.size())\n",
    "print(C.size()[0])\n",
    "print(\"矩阵C的参数个数是:\")\n",
    "print(C.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random matrix, r:\n",
      "tensor([[-0.3800, -0.6651],\n",
      "        [-0.2677, -0.2651]])\n",
      "\n",
      "Absolute value of r:\n",
      "tensor([[0.3800, 0.6651],\n",
      "        [0.2677, 0.2651]])\n",
      "\n",
      "Inverse sine of r:\n",
      "tensor([[-0.3898, -0.7277],\n",
      "        [-0.2710, -0.2683]])\n",
      "\n",
      "Determinant of r:\n",
      "tensor(-0.0773)\n",
      "\n",
      "Singular value decomposition of r:\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.9013, -0.4332],\n",
      "        [-0.4332,  0.9013]]),\n",
      "S=tensor([0.8488, 0.0911]),\n",
      "V=tensor([[ 0.5401, -0.8416],\n",
      "        [ 0.8416,  0.5401]]))\n",
      "\n",
      "Average and standard deviation of r:\n",
      "(tensor(0.1882), tensor(-0.3945))\n",
      "\n",
      "Maximum value of r:\n",
      "tensor(-0.2651)\n"
     ]
    }
   ],
   "source": [
    "#数学操作\n",
    "r = torch.rand(2, 2) - 0.5 * 2 # values between -1 and 1\n",
    "print('A random matrix, r:')\n",
    "print(r)\n",
    "\n",
    "# Common mathematical operations are supported:\n",
    "print('\\nAbsolute value of r:')\n",
    "print(torch.abs(r))\n",
    "\n",
    "# ...as are trigonometric functions:\n",
    "print('\\nInverse sine of r:')\n",
    "print(torch.asin(r))\n",
    "\n",
    "# ...and linear algebra operations like determinant and singular value decomposition\n",
    "print('\\nDeterminant of r:')\n",
    "print(torch.det(r))\n",
    "print('\\nSingular value decomposition of r:')\n",
    "print(torch.svd(r))\n",
    "\n",
    "# ...and statistical and aggregate operations:\n",
    "print('\\nAverage and standard deviation of r:')\n",
    "print(torch.std_mean(r))\n",
    "print('\\nMaximum value of r:')\n",
    "print(torch.max(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.自动求导机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3870, -0.6919,  0.0053, -1.2286],\n",
      "        [ 1.0824, -0.5188,  0.3686, -2.5254],\n",
      "        [ 1.2152, -0.1251, -2.2646, -0.4037]], requires_grad=True)\n",
      "D对B求导得:\n",
      "tensor([[-0.7739, -1.3838,  0.0106, -2.4572],\n",
      "        [ 2.1648, -1.0376,  0.7371, -5.0508],\n",
      "        [ 2.4304, -0.2503, -4.5293, -0.8074]])\n"
     ]
    }
   ],
   "source": [
    "A=torch.ones(3,4)\n",
    "B=torch.randn(3,4)\n",
    "B.requires_grad=True\n",
    "A.requires_grad=True\n",
    "print(B)\n",
    "C=A+B*B\n",
    "D=C.sum()\n",
    "D.to('cpu')\n",
    "D.backward()\n",
    "print('D对B求导得:')\n",
    "print(B.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
